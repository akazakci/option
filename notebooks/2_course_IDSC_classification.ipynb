{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"course_IDSC_classification.ipynb","provenance":[{"file_id":"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/classification.ipynb","timestamp":1633118896953}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"FE7KNzPPVrVV"},"source":["# Image classification"]},{"cell_type":"markdown","metadata":{"id":"zF9uvbXNVrVY"},"source":["## Import TensorFlow and other libraries"]},{"cell_type":"code","metadata":{"id":"L1WtoaOHVrVh"},"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","import PIL\n","import tensorflow as tf\n","\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras.models import Sequential"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UZZI6lNkVrVm"},"source":["## Download and explore the dataset"]},{"cell_type":"markdown","metadata":{"id":"DPHx8-t-VrVo"},"source":["We use 1000 images. The dataset contains two sub-directories, one per class:\n","\n","```\n","images/\n","  with_mask/\n","  without_mask/\n","```"]},{"cell_type":"code","metadata":{"id":"57CcilYSG0zv"},"source":["import pathlib\n","!gdown --id 1-VwggI9SN2alttcNEX7eQ8VaICk7XVce\n","!unzip \"dataset_classification_masks.zip\"\n","data_dir = pathlib.Path(\"./images\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VpmywIlsVrVx"},"source":["After downloading, you should now have a copy of the dataset available. There are 1000 total images:"]},{"cell_type":"code","metadata":{"id":"SbtTDYhOHZb6"},"source":["image_count = len(list(data_dir.glob('*/*.png')))\n","print(image_count)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PVmwkOSdHZ5A"},"source":["Here are some images:"]},{"cell_type":"code","metadata":{"id":"N1loMlbYHeiJ"},"source":["images = list(data_dir.glob('with_mask/*'))\n","PIL.Image.open(str(images[1]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RQbZBOTLHiUP"},"source":["PIL.Image.open(str(images[5]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HyQkfPGdHilw"},"source":["images = list(data_dir.glob('without_mask/*'))\n","PIL.Image.open(str(images[13]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wtlhWJPAHivf"},"source":["PIL.Image.open(str(images[4]))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gIjgz7_JIo_m"},"source":["# Load data using a Keras utility\n","\n","Let's load these images off disk using the helpful `tf.keras.utils.image_dataset_from_directory` utility. This will take you from a directory of images on disk to a `tf.data.Dataset` in just a couple lines of code. If you like, you can also write your own data loading code from scratch by visiting the [Load and preprocess images](../load_data/images.ipynb) tutorial."]},{"cell_type":"markdown","metadata":{"id":"xyDNn9MbIzfT"},"source":["## Create a dataset"]},{"cell_type":"markdown","metadata":{"id":"anqiK_AGI086"},"source":["Define some parameters for the loader:"]},{"cell_type":"code","metadata":{"id":"H74l2DoDI2XD"},"source":["batch_size = 32\n","img_height = 180\n","img_width = 180"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pFBhRrrEI49z"},"source":["It's good practice to use a validation split when developing your model. Let's use 80% of the images for training, and 20% for validation."]},{"cell_type":"code","metadata":{"id":"fIR0kRZiI_AT"},"source":["train_ds = tf.keras.utils.image_dataset_from_directory(\n","  data_dir,\n","  validation_split=0.2,\n","  subset=\"training\",\n","  seed=123,\n","  image_size=(img_height, img_width),\n","  batch_size=batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iscU3UoVJBXj"},"source":["val_ds = tf.keras.utils.image_dataset_from_directory(\n","  data_dir,\n","  validation_split=0.2,\n","  subset=\"validation\",\n","  seed=123,\n","  image_size=(img_height, img_width),\n","  batch_size=batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WLQULyAvJC3X"},"source":["You can find the class names in the `class_names` attribute on these datasets. These correspond to the directory names in alphabetical order."]},{"cell_type":"code","metadata":{"id":"ZHAxkHX5JD3k"},"source":["class_names = train_ds.class_names\n","print(class_names)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_uoVvxSLJW9m"},"source":["## Visualize the data\n","\n","Here are the first nine images from the training dataset:"]},{"cell_type":"code","metadata":{"id":"wBmEA9c0JYes"},"source":["import matplotlib.pyplot as plt\n","\n","plt.figure(figsize=(10, 10))\n","for images, labels in train_ds.take(1):\n","  for i in range(9):\n","    ax = plt.subplot(3, 3, i + 1)\n","    plt.imshow(images[i].numpy().astype(\"uint8\"))\n","    plt.title(class_names[labels[i]])\n","    plt.axis(\"off\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5M6BXtXFJdW0"},"source":["You will train a model using these datasets by passing them to `Model.fit` in a moment. If you like, you can also manually iterate over the dataset and retrieve batches of images:"]},{"cell_type":"code","metadata":{"id":"2-MfMoenJi8s"},"source":["for image_batch, labels_batch in train_ds:\n","  print(image_batch.shape)\n","  print(labels_batch.shape)\n","  break"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Wj4FrKxxJkoW"},"source":["The `image_batch` is a tensor of the shape `(32, 180, 180, 3)`. This is a batch of 32 images of shape `180x180x3` (the last dimension refers to color channels RGB). The `label_batch` is a tensor of the shape `(32,)`, these are corresponding labels to the 32 images.\n","\n","You can call `.numpy()` on the `image_batch` and `labels_batch` tensors to convert them to a `numpy.ndarray`.\n"]},{"cell_type":"markdown","metadata":{"id":"4Dr0at41KcAU"},"source":["## Configure the dataset for performance\n","\n","Let's make sure to use buffered prefetching so you can yield data from disk without having I/O become blocking. These are two important methods you should use when loading data:\n","\n","- `Dataset.cache` keeps the images in memory after they're loaded off disk during the first epoch. This will ensure the dataset does not become a bottleneck while training your model. If your dataset is too large to fit into memory, you can also use this method to create a performant on-disk cache.\n","- `Dataset.prefetch` overlaps data preprocessing and model execution while training.\n","\n","Interested readers can learn more about both methods, as well as how to cache data to disk in the *Prefetching* section of the [Better performance with the tf.data API](../../guide/data_performance.ipynb) guide."]},{"cell_type":"code","metadata":{"id":"nOjJSm7DKoZA"},"source":["AUTOTUNE = tf.data.AUTOTUNE\n","\n","train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n","val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8GUnmPF4JvEf"},"source":["## Standardize the data"]},{"cell_type":"markdown","metadata":{"id":"e56VXHMWJxYT"},"source":["The RGB channel values are in the `[0, 255]` range. This is not ideal for a neural network; in general you should seek to make your input values small.\n","\n","Here, you will standardize values to be in the `[0, 1]` range by using `tf.keras.layers.Rescaling`:"]},{"cell_type":"code","metadata":{"id":"PEYxo2CTJvY9"},"source":["normalization_layer = layers.Rescaling(1./255)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WcUTyDOPKucd"},"source":["# Create the model\n","\n","The [Sequential](../../guide/keras/sequential_model.ipynb) model consists of three convolution blocks (`tf.keras.layers.Conv2D`) with a max pooling layer (`tf.keras.layers.MaxPooling2D`) in each of them. There's a fully-connected layer (`tf.keras.layers.Dense`) with 128 units on top of it that is activated by a ReLU activation function (`'relu'`). This model has not been tuned for high accuracyâ€”the goal of this tutorial is to show a standard approach."]},{"cell_type":"code","metadata":{"id":"QR6argA1K074"},"source":["num_classes = 2\n","\n","model = Sequential([\n","  layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n","  #complete code\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EaKFzz72Lqpg"},"source":["## Compile the model\n","\n","For this tutorial, choose the `tf.keras.optimizers.Adam` optimizer and `tf.keras.losses.SparseCategoricalCrossentropy` loss function. To view training and validation accuracy for each training epoch, pass the `metrics` argument to `Model.compile`."]},{"cell_type":"code","metadata":{"id":"jloGNS1MLx3A"},"source":["model.compile(optimizer='adam',\n","              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","              metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aMJ4DnuJL55A"},"source":["## Model summary\n","\n","View all the layers of the network using the model's `Model.summary` method:"]},{"cell_type":"code","metadata":{"id":"llLYH-BXL7Xe"},"source":["model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NiYHcbvaL9H-"},"source":["## Train the model"]},{"cell_type":"code","metadata":{"id":"5fWToCqYMErH"},"source":["!mkdir /content/training\n","checkpoint_path = \"/content/training/cp.ckpt\"\n","checkpoint_dir = os.path.dirname(checkpoint_path)\n","\n","cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,save_weights_only=True,verbose=1)\n","\n","epochs=10\n","history = model.fit(\n","  train_ds,\n","  validation_data=val_ds,\n","  epochs=epochs,\n","  callbacks=[cp_callback]\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zReO9gO8STYW"},"source":["## Download weights"]},{"cell_type":"code","metadata":{"id":"LPETDXWHSAoN"},"source":["%cd /content/training/\n","!zip -r weights.zip  .\n","from google.colab import files\n","#files.download(\"/content/weights.zip\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SyFKdQpXMJT4"},"source":["## Visualize training results"]},{"cell_type":"markdown","metadata":{"id":"dFvOvmAmMK9w"},"source":["Create plots of loss and accuracy on the training and validation sets:"]},{"cell_type":"code","metadata":{"id":"jWnopEChMMCn"},"source":["acc = history.history['accuracy']\n","val_acc = history.history['val_accuracy']\n","\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","epochs_range = range(epochs)\n","\n","plt.figure(figsize=(8, 8))\n","plt.subplot(1, 2, 1)\n","plt.plot(epochs_range, acc, label='Training Accuracy')\n","plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n","plt.legend(loc='lower right')\n","plt.title('Training and Validation Accuracy')\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(epochs_range, loss, label='Training Loss')\n","plt.plot(epochs_range, val_loss, label='Validation Loss')\n","plt.legend(loc='upper right')\n","plt.title('Training and Validation Loss')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BDMfYqwmM1C-"},"source":["## Data augmentation"]},{"cell_type":"markdown","metadata":{"id":"GxYwix81M2YO"},"source":["\n","You will implement data augmentation using the following Keras preprocessing layers: `tf.keras.layers.RandomFlip`, `tf.keras.layers.RandomRotation`, and `tf.keras.layers.RandomZoom`. These can be included inside your model like other layers, and run on the GPU."]},{"cell_type":"code","metadata":{"id":"9J80BAbIMs21"},"source":["data_augmentation = keras.Sequential(\n","  [\n","    layers.RandomFlip(\"horizontal\",\n","                      input_shape=(img_height,\n","                                  img_width,\n","                                  3)),\n","    layers.RandomRotation(0.1),\n","    layers.RandomZoom(0.1),\n","  ]\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PN4k1dK3S6eV"},"source":["Let's visualize what a few augmented examples look like by applying data augmentation to the same image several times:"]},{"cell_type":"code","metadata":{"id":"7Z90k539S838"},"source":["plt.figure(figsize=(10, 10))\n","for images, _ in train_ds.take(1):\n","  for i in range(9):\n","    augmented_images = data_augmentation(images)\n","    ax = plt.subplot(3, 3, i + 1)\n","    plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n","    plt.axis(\"off\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tsjXCBLYYNs5"},"source":["You will use data augmentation to train a model in a moment."]},{"cell_type":"markdown","metadata":{"id":"ZeD3bXepYKXs"},"source":["## Dropout\n","\n","\n","When you apply dropout to a layer, it randomly drops out (by setting the activation to zero) a number of output units from the layer during the training process. Dropout takes a fractional number as its input value, in the form such as 0.1, 0.2, 0.4, etc. This means dropping out 10%, 20% or 40% of the output units randomly from the applied layer.\n","\n","Let's create a new neural network with `tf.keras.layers.Dropout` before training it using the augmented images:"]},{"cell_type":"code","metadata":{"id":"2Zeg8zsqXCsm"},"source":["model = Sequential([\n","  data_augmentation,\n","  layers.Rescaling(1./255),\n","  # complete code\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L4nEcuqgZLbi"},"source":["## Compile and train the model"]},{"cell_type":"code","metadata":{"id":"EvyAINs9ZOmJ"},"source":["model.compile(optimizer='adam',\n","              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","              metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wWLkKoKjZSoC"},"source":["model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LWS-vvNaZDag"},"source":["epochs = 15\n","history = model.fit(\n","  train_ds,\n","  validation_data=val_ds,\n","  epochs=epochs\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Lkdl8VsBbZOu"},"source":["## Visualize training results\n"]},{"cell_type":"code","metadata":{"id":"dduoLfKsZVIA"},"source":["acc = history.history['accuracy']\n","val_acc = history.history['val_accuracy']\n","\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","epochs_range = range(epochs)\n","\n","plt.figure(figsize=(8, 8))\n","plt.subplot(1, 2, 1)\n","plt.plot(epochs_range, acc, label='Training Accuracy')\n","plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n","plt.legend(loc='lower right')\n","plt.title('Training and Validation Accuracy')\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(epochs_range, loss, label='Training Loss')\n","plt.plot(epochs_range, val_loss, label='Validation Loss')\n","plt.legend(loc='upper right')\n","plt.title('Training and Validation Loss')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dtv5VbaVb-3W"},"source":["## Predict on new data"]},{"cell_type":"markdown","metadata":{"id":"10buWpJbcCQz"},"source":["Finally, let's use our model to classify an image that wasn't included in the training or validation sets."]},{"cell_type":"markdown","metadata":{"id":"NKgMZ4bDcHf7"},"source":["Note: Data augmentation and dropout layers are inactive at inference time."]},{"cell_type":"code","metadata":{"id":"a-G8NwOas-NV"},"source":["!gdown --id 1sjzx4XvbsR4K2JQrfUh_c-Y8gAvLjVLw\n","!unzip \"classification_examples.zip\"\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dC40sRITBSsQ"},"source":["\n","img = tf.keras.utils.load_img(\n","    \"examples/without_mask/maksssksksss217_0.png\", target_size=(img_height, img_width)\n",")\n","img_array = tf.keras.utils.img_to_array(img)\n","img_array = tf.expand_dims(img_array, 0) # Create a batch\n","\n","predictions = model.predict(img_array)\n","score = tf.nn.softmax(predictions[0])\n","\n","print(\n","    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n","    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",")"],"execution_count":null,"outputs":[]}]}